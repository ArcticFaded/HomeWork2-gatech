{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.2 (default, Feb 10 2019, 08:04:56) \n",
      "[Clang 10.0.0 (clang-1000.10.44.4)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import mlrose\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {\n",
    "    'genetic_algorithm': [],\n",
    "    'simulated_annealing': [],\n",
    "    'random_hill_climbing': [],\n",
    "    'MIMIC': []\n",
    "}\n",
    "\n",
    "for x in [10, 20, 30, 40, 50]:\n",
    "    def generate_knapsack(size):\n",
    "        capacity = 0.6\n",
    "        np.random.seed(42)\n",
    "        weights = np.array(sorted(np.random.randint(10, 90, size=size)))\n",
    "        values = [np.random.randint(int(weight/2), weight) for weight in weights]\n",
    "#         items = np.random.randint(10, 90, size=(size,2))\n",
    "# #         items = sorted(items, key=lambda x: x[0])\n",
    "# #         items = np.array([list(i) for i in items])\n",
    "#         weights, values = items[:,0], items[:, 1]\n",
    "\n",
    "        print(weights, values)\n",
    "        print(np.sum(weights), np.sum(weights)*capacity)\n",
    "\n",
    "        max_weight_pct=capacity\n",
    "\n",
    "        fitness = mlrose.Knapsack(weights, values, max_weight_pct)\n",
    "\n",
    "        return fitness, weights, values\n",
    "\n",
    "    fitness, weights, values = generate_knapsack(x)\n",
    "    #print(fitness.evaluate(state))\n",
    "    np.random.seed(42)\n",
    "    problem = mlrose.DiscreteOpt(length = x, \n",
    "                                 fitness_fn = fitness, \n",
    "                                 maximize = True, \n",
    "                                 max_val = 3)\n",
    "\n",
    "    # np.random.seed(42)\n",
    "    start = time.time()\n",
    "    best_state, best_fitness, iters = mlrose.genetic_alg(problem, pop_size=500, mutation_prob = 0.2, max_attempts = 500)\n",
    "    end = time.time()\n",
    "    answers['genetic_algorithm'].append((best_state, best_fitness, end-start))\n",
    "\n",
    "    print('genetic algorithm')\n",
    "    print(np.dot(best_state, weights), 'weight capacity')\n",
    "    print(np.dot(best_state, values), 'value')\n",
    "\n",
    "    #np.random.seed(42)\n",
    "    init_state = np.random.randint(0, 2, size=x)\n",
    "\n",
    "    schedule = mlrose.ExpDecay(init_temp=1, exp_const=0.95, min_temp=0.001)\n",
    "    start = time.time()\n",
    "    best_state, best_fitness = mlrose.simulated_annealing(problem, schedule = schedule,\n",
    "                                                          max_attempts = 20,\n",
    "                                                          init_state = init_state)\n",
    "    end = time.time()\n",
    "    answers['simulated_annealing'].append((best_state, best_fitness, end-start))\n",
    "    print('simulated_annealing')\n",
    "    print(np.dot(best_state, weights), 'weight capacity')\n",
    "    print(np.dot(best_state, values), 'value')\n",
    "\n",
    "    start = time.time()\n",
    "    best_state, best_fitness = mlrose.random_hill_climb(problem, max_attempts = 300, restarts=20,\n",
    "                                                          init_state = init_state)\n",
    "    end = time.time()\n",
    "    answers['random_hill_climbing'].append((best_state, best_fitness, end-start))\n",
    "    print('random_hill_climbing')\n",
    "    print(np.dot(best_state, weights), 'weight capacity')\n",
    "    print(np.dot(best_state, values), 'value')\n",
    "\n",
    "    start = time.time()\n",
    "    best_state, best_fitness = mlrose.mimic(problem, pop_size=500, keep_pct = 0.2, max_attempts = 500)\n",
    "    end = time.time()\n",
    "    answers['MIMIC'].append((best_state, best_fitness, end-start))\n",
    "    print('mimic')\n",
    "    print(np.dot(best_state, weights))\n",
    "    print(np.dot(best_state, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "genetic_iters = [523, 854, 712, 615, 728]\n",
    "simulated_iters = [120, 25, 22, 39, 40]\n",
    "random_iters = [6519, 6564, 6803, 6961, 6790]\n",
    "mimic_iters = [502, 512, 518, 689, 606]\n",
    "\n",
    "answers_iters = {\n",
    "    'genetic_algorithm': genetic_iters,\n",
    "    'simulated_annealing': simulated_iters,\n",
    "    'random_hill_climbing': random_iters,\n",
    "    'MIMIC': mimic_iters\n",
    "}\n",
    "\n",
    "colors = ['r', 'b', 'g', 'y']\n",
    "j = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('fitness vs input size')\n",
    "for key, value in answers.items():\n",
    "    print(key, [x[1] for x in value])\n",
    "    fitness = [x[1] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], fitness, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Optimal Value')\n",
    "plt.legend()\n",
    "plt.savefig('InputOptimal_3_60')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('iterations vs input size')\n",
    "j=0\n",
    "for key, value in answers_iters.items():\n",
    "    ax.plot([10, 20, 30, 40, 50], value, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Iterations')\n",
    "plt.legend()\n",
    "plt.savefig('InputIteration_3_60')\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('time vs input size')\n",
    "for key, value in answers.items():\n",
    "    times = [x[2] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], times, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Time in Seconds')\n",
    "plt.legend()\n",
    "plt.savefig('InputTime_3_60')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "\n",
    "graph = networkx.connected_watts_strogatz_graph(9, 3, 0.5, 5)\n",
    "edges = graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "colors_of_nodes = networkx.greedy_color(graph)\n",
    "networkx.draw_shell(graph, node_color= 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_answers = {\n",
    "    'genetic_algorithm': {\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: []\n",
    "    },\n",
    "    'simulated_annealing': {\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: []\n",
    "    },\n",
    "    'random_hill_climbing': {\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: []\n",
    "    },\n",
    "    'MIMIC': {\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: []\n",
    "    }\n",
    "}\n",
    "\n",
    "for x in [9, 16, 25, 36, 49]:\n",
    "    for k in range(2, min(x, 7)):\n",
    "        graph = networkx.connected_watts_strogatz_graph(x, k, 0.5, 5)\n",
    "        edges = graph.edges\n",
    "        fitness = mlrose.MaxKColor(edges)\n",
    "        \n",
    "        current_fitness = 1\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        problem = mlrose.DiscreteOpt(length = x, \n",
    "                                     fitness_fn = fitness, \n",
    "                                     maximize = True, \n",
    "                                     max_val = k)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        start = time.time()\n",
    "        best_state, best_fitness, iters = mlrose.genetic_alg(problem, \n",
    "                                                             mutation_prob = 0.2, \n",
    "                                                             max_attempts = 20, \n",
    "                                                             pop_size=500)\n",
    "        end = time.time()\n",
    "        # networkx.draw(graph, node_color=best_state)\n",
    "        plt.show()\n",
    "        graph_answers['genetic_algorithm'][k].append((best_state, best_fitness, end-start, iters))\n",
    "        print('genetic_algorithm', best_state, best_fitness, end-start)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        init_state = np.random.randint(0,k-1, size=x)\n",
    "\n",
    "        schedule = mlrose.ExpDecay(init_temp=1, exp_const=0.5, min_temp=0.1)\n",
    "        start = time.time()\n",
    "        best_state, best_fitness, iters = mlrose.simulated_annealing(problem, schedule = schedule,\n",
    "                                                              max_attempts = 50, max_iters = 5000,\n",
    "                                                              init_state = init_state)\n",
    "        end = time.time()\n",
    "        # networkx.draw_shell(graph, node_color=best_state)\n",
    "        plt.show()\n",
    "        graph_answers['simulated_annealing'][k].append((best_state, best_fitness, end-start, iters))\n",
    "        print('simulated_annealing', best_state, best_fitness, end-start)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        init_state = np.random.randint(0,k-1, size=x)\n",
    "\n",
    "        start = time.time()\n",
    "        best_state, best_fitness, iters = mlrose.random_hill_climb(problem, \n",
    "                                                                   max_attempts = 100, \n",
    "                                                                   restarts=50,\n",
    "                                                                   max_iters = 200,\n",
    "                                                              init_state = init_state)\n",
    "        end = time.time()\n",
    "        # networkx.draw(graph, node_color=best_state)\n",
    "        plt.show()\n",
    "        graph_answers['random_hill_climbing'][k].append((best_state, best_fitness, end-start, iters))\n",
    "        print('random_hill_climbing', best_state, best_fitness, end-start)\n",
    "\n",
    "        start = time.time()\n",
    "        best_state, best_fitness, iters = mlrose.mimic(problem, pop_size=500, keep_pct = 0.5, max_attempts = 20)\n",
    "        end = time.time()\n",
    "        # networkx.draw(graph, node_color=best_state)\n",
    "        plt.show()\n",
    "        graph_answers['MIMIC'][k].append((best_state, best_fitness, end-start, iters))\n",
    "        print('MIMIC', best_state, best_fitness, end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfun(x):\n",
    "    print (x)\n",
    "    return x[1] == 0\n",
    "\n",
    "def filter_smallest_fitness(enumerable_fitness):\n",
    "     # another filter needs to be applied\n",
    "#     print(enumerable_fitness)\n",
    "    answered_in = {\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: [],\n",
    "        6: []\n",
    "    }\n",
    "    for key, value in enumerable_fitness: #key is K\n",
    "        #print(key, value)\n",
    "        current_size = 0\n",
    "        while value[current_size][1] == 0:\n",
    "            answered_in[key].append((current_size, value[current_size][2]))\n",
    "            current_size += 1\n",
    "            if current_size == 5:\n",
    "                break\n",
    "        \n",
    "        \n",
    "    \n",
    "    return answered_in\n",
    "\n",
    "for algorithm in graph_answers.keys():\n",
    "    answers_ = filter_smallest_fitness(graph_answers[algorithm].items())\n",
    "    filled = 0\n",
    "    min_time = {\n",
    "        2: 60.0,\n",
    "        3: 60.0,\n",
    "        4: 60.0, \n",
    "        5: 60.0, \n",
    "        6: 60.0\n",
    "    }\n",
    "    min_value = {\n",
    "        9: 6.0,\n",
    "        16: 6.0,\n",
    "        25: 6.0, \n",
    "        36: 6.0, \n",
    "        49: 6.0\n",
    "    }\n",
    "    for K, answers in answers_.items():\n",
    "        for tups in answers:\n",
    "            k, times = tups\n",
    "            if (k == filled):\n",
    "                min_value[(filled+3)**2] = K\n",
    "                min_time[filled+2] = times\n",
    "                filled += 1\n",
    "    print(algorithm, min_time, min_value)\n",
    "    plt.plot(min_value.keys(), min_time.values(), marker='o', label=algorithm)\n",
    "\n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('time to find K')\n",
    "plt.title('Time vs input size')\n",
    "plt.legend()\n",
    "plt.savefig('MaxKTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "answers_iters = {\n",
    "    'genetic_algorithm': genetic_iters,\n",
    "    'simulated_annealing': simulated_iters,\n",
    "    'random_hill_climbing': random_iters,\n",
    "    'MIMIC': mimic_iters\n",
    "}\n",
    "\n",
    "colors = ['r', 'b', 'g', 'y']\n",
    "j = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('fitness vs input size')\n",
    "for key, value in answers.items():\n",
    "    print(key, [x[1] for x in value])\n",
    "    fitness = [x[1] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], fitness, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Optimal Value')\n",
    "plt.legend()\n",
    "plt.savefig('InputOptimal_3_60')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('iterations vs input size')\n",
    "j=0\n",
    "for key, value in answers_iters.items():\n",
    "    ax.plot([10, 20, 30, 40, 50], value, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Iterations')\n",
    "plt.legend()\n",
    "plt.savefig('InputIteration_3_60')\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('time vs input size')\n",
    "for key, value in answers.items():\n",
    "    times = [x[2] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], times, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Time in Seconds')\n",
    "plt.legend()\n",
    "plt.savefig('InputTime_3_60')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_four = {\n",
    "    'genetic_algorithm': [],\n",
    "    'simulated_annealing': [],\n",
    "    'random_hill_climbing': [],\n",
    "    'MIMIC': []\n",
    "}\n",
    "\n",
    "for size in [10, 20, 30, 40, 50]:\n",
    "    fitness = mlrose.FourPeaks(t_pct=0.15)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    problem = mlrose.DiscreteOpt(length = size, \n",
    "                                 fitness_fn = fitness, \n",
    "                                 maximize = True, \n",
    "                                 max_val = 2)\n",
    "\n",
    "    # np.random.seed(42)\n",
    "    start = time.time()\n",
    "    best_state, best_fitness, iters = mlrose.genetic_alg(problem, pop_size=500, mutation_prob = 0.1, max_attempts = 20)\n",
    "    end = time.time()\n",
    "    print('genetic_algorithm')\n",
    "    answers_four['genetic_algorithm'].append((best_state, best_fitness, end-start, iters))\n",
    "    print(best_state, best_fitness)\n",
    "\n",
    "    #np.random.seed(42)\n",
    "    init_state = np.random.randint(0,1, size=size)\n",
    "\n",
    "    schedule = mlrose.ExpDecay(init_temp=1, exp_const=0.95, min_temp=0.1)\n",
    "    start = time.time()\n",
    "    best_state, best_fitness, iters = mlrose.simulated_annealing(problem, schedule = schedule,\n",
    "                                                          max_attempts = 2000,\n",
    "                                                          init_state = init_state)\n",
    "    end = time.time()\n",
    "    print('simulated_annealing')\n",
    "    answers_four['simulated_annealing'].append((best_state, best_fitness, end-start, iters))\n",
    "    print(best_state, best_fitness)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    best_state, best_fitness, iters = mlrose.random_hill_climb(problem, max_attempts = 2000, restarts=20,\n",
    "                                                          init_state = init_state)\n",
    "    end = time.time()\n",
    "\n",
    "    print('random_hill_climbing')\n",
    "    answers_four['random_hill_climbing'].append((best_state, best_fitness, end-start, iters))\n",
    "    print(best_state, best_fitness)\n",
    "\n",
    "    start = time.time()\n",
    "    best_state, best_fitness, iters = mlrose.mimic(problem, pop_size=500, keep_pct = 0.1, max_attempts = 20)\n",
    "\n",
    "    end = time.time()\n",
    "    print('mimic')\n",
    "    answers_four['MIMIC'].append((best_state, best_fitness, end-start, iters))\n",
    "    print(best_state, best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = ['r', 'b', 'g', 'y']\n",
    "j = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('fitness vs input size')\n",
    "for key, value in answers_four.items():\n",
    "    fitness = [x[1] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], fitness, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Optimal Value')\n",
    "plt.legend()\n",
    "plt.savefig('InputOptimal_4')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('iterations vs input size')\n",
    "j=0\n",
    "for key, value in answers_four.items():\n",
    "    iters = [x[3] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], iters, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Iterations')\n",
    "plt.legend()\n",
    "plt.savefig('InputIteration_4')\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('time vs input size')\n",
    "for key, value in answers_four.items():\n",
    "    times = [x[2] for x in value]\n",
    "    ax.plot([10, 20, 30, 40, 50], times, marker='o', color=colors[j], label=key)\n",
    "    j=j+1\n",
    "    \n",
    "plt.xlabel('Input Size')\n",
    "plt.ylabel('Time in Seconds')\n",
    "plt.legend()\n",
    "plt.savefig('InputTime_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_hill_climb | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.88      0.51      0.64        71\n",
      "\n",
      "   micro avg       0.47      0.47      0.47        76\n",
      "   macro avg       0.44      0.25      0.32        76\n",
      "weighted avg       0.82      0.47      0.60        76\n",
      "\n",
      "random_hill_climb | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.38      0.14        24\n",
      "           1       0.88      0.54      0.67       203\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       227\n",
      "   macro avg       0.48      0.46      0.40       227\n",
      "weighted avg       0.80      0.52      0.61       227\n",
      "\n",
      "simulated_annealing | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.21      0.12        14\n",
      "           1       0.73      0.48      0.58        62\n",
      "\n",
      "   micro avg       0.43      0.43      0.43        76\n",
      "   macro avg       0.41      0.35      0.35        76\n",
      "weighted avg       0.61      0.43      0.50        76\n",
      "\n",
      "simulated_annealing | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.43      0.23        37\n",
      "           1       0.83      0.54      0.66       190\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       227\n",
      "   macro avg       0.49      0.49      0.44       227\n",
      "weighted avg       0.72      0.52      0.59       227\n",
      "\n",
      "random_hill_climb | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.92      0.50        13\n",
      "           1       0.98      0.63      0.77        63\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        76\n",
      "   macro avg       0.66      0.78      0.63        76\n",
      "weighted avg       0.87      0.68      0.72        76\n",
      "\n",
      "random_hill_climb | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.94      0.47        34\n",
      "           1       0.98      0.63      0.77       193\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       227\n",
      "   macro avg       0.65      0.79      0.62       227\n",
      "weighted avg       0.88      0.68      0.72       227\n",
      "\n",
      "simulated_annealing | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.63      0.74        49\n",
      "           1       0.56      0.85      0.68        27\n",
      "\n",
      "   micro avg       0.71      0.71      0.71        76\n",
      "   macro avg       0.72      0.74      0.71        76\n",
      "weighted avg       0.77      0.71      0.72        76\n",
      "\n",
      "simulated_annealing | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.57      0.67       147\n",
      "           1       0.49      0.76      0.60        80\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       227\n",
      "   macro avg       0.65      0.67      0.64       227\n",
      "weighted avg       0.70      0.64      0.65       227\n",
      "\n",
      "random_hill_climb | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72        34\n",
      "           1       0.78      0.76      0.77        42\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        76\n",
      "   macro avg       0.75      0.75      0.75        76\n",
      "weighted avg       0.75      0.75      0.75        76\n",
      "\n",
      "random_hill_climb | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       101\n",
      "           1       0.80      0.79      0.79       126\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       227\n",
      "   macro avg       0.77      0.77      0.77       227\n",
      "weighted avg       0.77      0.77      0.77       227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated_annealing | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63        76\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.46      0.46      0.46        76\n",
      "   macro avg       0.50      0.23      0.32        76\n",
      "weighted avg       1.00      0.46      0.63        76\n",
      "\n",
      "simulated_annealing | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.44      0.61       223\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       227\n",
      "   macro avg       0.48      0.22      0.30       227\n",
      "weighted avg       0.94      0.44      0.60       227\n",
      "\n",
      "random_hill_climb | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80        30\n",
      "           1       0.90      0.80      0.85        46\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        76\n",
      "   macro avg       0.82      0.84      0.83        76\n",
      "weighted avg       0.84      0.83      0.83        76\n",
      "\n",
      "random_hill_climb | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94        98\n",
      "           1       0.97      0.93      0.95       129\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       227\n",
      "   macro avg       0.94      0.94      0.94       227\n",
      "weighted avg       0.94      0.94      0.94       227\n",
      "\n",
      "simulated_annealing | test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82        36\n",
      "           1       0.83      0.85      0.84        40\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        76\n",
      "   macro avg       0.83      0.83      0.83        76\n",
      "weighted avg       0.83      0.83      0.83        76\n",
      "\n",
      "simulated_annealing | train \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89       109\n",
      "           1       0.88      0.92      0.90       118\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       227\n",
      "   macro avg       0.90      0.89      0.89       227\n",
      "weighted avg       0.90      0.89      0.89       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from functools import reduce\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "MODEL: INPUTS -> 12 hidden units -> 8 hidden units -> 1 output\n",
    "\n",
    "\n",
    "def create_model(input_dim):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_heart_data(heart):\n",
    "    chest_pains = pd.get_dummies(heart.cp, prefix='cp')\n",
    "    slopes = pd.get_dummies(heart.slope, prefix='slope')\n",
    "    major_vessels = pd.get_dummies(heart.ca, prefix='ca')\n",
    "    thals = pd.get_dummies(heart.thal, prefix='thals')\n",
    "\n",
    "    processed_csv = [\n",
    "        chest_pains,\n",
    "        slopes,\n",
    "        major_vessels,\n",
    "        thals,\n",
    "        heart[['age', 'sex', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak']],\n",
    "        pd.DataFrame(heart.target)\n",
    "    ]\n",
    "\n",
    "    df_final = reduce(lambda left, right: pd.merge(left, right, left_index=True, right_index=True), processed_csv)\n",
    "\n",
    "    # scaling\n",
    "    norm_columns = ['age', 'trestbps', 'chol', 'restecg', 'thalach', 'oldpeak']\n",
    "\n",
    "    scalers = {name: MinMaxScaler() for name in norm_columns}\n",
    "\n",
    "    for names in norm_columns:\n",
    "        df_final[names] = scalers[names].fit_transform(df_final[[names]])\n",
    "        \n",
    "    return df_final, scalers\n",
    "\n",
    "answers_nn = {\n",
    "    'genetic_algorithm': [],\n",
    "    'simulated_annealing': [],\n",
    "    'random_hill_climbing': []\n",
    "}\n",
    "\n",
    "heart = pd.read_csv('./heart-prediction/heart.csv')\n",
    "heart_final, heart_scalers = preprocess_heart_data(heart)\n",
    "\n",
    "\n",
    "X = heart_final.loc[:, heart_final.columns != 'target']\n",
    "Y = heart_final.loc[:, heart_final.columns == 'target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "# # Initialize neural network object and fit object\n",
    "# np.random.seed(42)\n",
    "for x in [0.0001, 0.001, 0.01, 0.1]:\n",
    "    nn_model2 = mlrose.NeuralNetworkClassifier(hidden_nodes = [12, 8], activation = 'relu', \\\n",
    "                                     algorithm = 'random_hill_climb', max_iters = 5000, \\\n",
    "                                     bias = True, learning_rate = x, \\\n",
    "                                     early_stopping = True, clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    nn_model2.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_pred = nn_model2.predict(X_test)\n",
    "    answers_nn['random_hill_climbing'].append((X_test, y_test_pred, y_test))\n",
    "    print('{classifer} \\n {report}'.format(\n",
    "                classifer='random_hill_climb | test', \n",
    "                report=classification_report(np.round(y_test_pred), y_test)\n",
    "            ))\n",
    "\n",
    "    y_train_pred = nn_model2.predict(X_train)\n",
    "\n",
    "    print('{classifer} \\n {report}'.format(\n",
    "                classifer='random_hill_climb | train', \n",
    "                report=classification_report(np.round(y_train_pred), y_train)\n",
    "            ))\n",
    "\n",
    "\n",
    "    schedule = mlrose.ExpDecay()\n",
    "    nn_model2 = mlrose.NeuralNetworkClassifier(hidden_nodes = [12, 8], schedule=schedule, activation = 'relu', \\\n",
    "                                     algorithm = 'simulated_annealing', max_iters = 5000, \\\n",
    "                                     bias = True, learning_rate = x, \\\n",
    "                                     early_stopping = True, clip_max = 5, max_attempts = 100)\n",
    "\n",
    "    nn_model2.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = nn_model2.predict(X_test)\n",
    "    answers_nn['simulated_annealing'].append((X_test, y_test_pred, y_test))\n",
    "    print('{classifer} \\n {report}'.format(\n",
    "                classifer='simulated_annealing | test', \n",
    "                report=classification_report(np.round(y_test_pred), y_test)\n",
    "            ))\n",
    "\n",
    "    y_train_pred = nn_model2.predict(X_train)\n",
    "\n",
    "    print('{classifer} \\n {report}'.format(\n",
    "                classifer='simulated_annealing | train', \n",
    "                report=classification_report(np.round(y_train_pred), y_train)\n",
    "            ))\n",
    "\n",
    "    np.seterr(all='ignore')\n",
    "#     np.random.seed(42)\n",
    "#     nn_model2 = mlrose.NeuralNetworkClassifier(hidden_nodes = [12, 8], activation = 'relu', \\\n",
    "#                                      algorithm = 'genetic_alg', pop_size=500, mutation_prob=0.35, \\\n",
    "#                                      bias = True, learning_rate = x, clip_max = 5, max_attempts = 500)\n",
    "\n",
    "\n",
    "\n",
    "#     nn_model2.fit(X_train, y_train)\n",
    "\n",
    "#     y_test_pred = nn_model2.predict(X_test)\n",
    "#     answers_nn['genetic_algorithm'].append((X_test, y_test_pred, y_test))\n",
    "#     print('{classifer} \\n {report}'.format(\n",
    "#                 classifer='genetic_alg | test', \n",
    "#                 report=classification_report(np.round(y_test_pred), y_test)\n",
    "#             ))\n",
    "\n",
    "#     y_train_pred = nn_model2.predict(X_train)\n",
    "\n",
    "#     print('{classifer} \\n {report}'.format(\n",
    "#                 classifer='genetic_alg | train', \n",
    "#                 report=classification_report(np.round(y_train_pred), y_train)\n",
    "#             ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [0.2, 0.3, 0.35, 0.4]:\n",
    "    np.seterr(all='ignore')\n",
    "    np.random.seed(42)\n",
    "    nn_model2 = mlrose.NeuralNetworkClassifier(hidden_nodes = [12, 8], activation = 'relu', \\\n",
    "                                     algorithm = 'genetic_alg', pop_size=500, mutation_prob=x, \\\n",
    "                                     bias = True, learning_rate = 0.0001, clip_max = 5, max_attempts = 500)\n",
    "\n",
    "\n",
    "\n",
    "    nn_model2.fit(X_train, y_train)\n",
    "\n",
    "    y_test_pred = nn_model2.predict(X_test)\n",
    "    answers_nn['genetic_algorithm'].append((X_test, y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.4342105263157895\n",
      "0.001 0.7105263157894737\n",
      "0.01 0.4605263157894737\n",
      "0.1 0.8289473684210527\n",
      "0.0001 0.47368421052631576\n",
      "0.001 0.6842105263157895\n",
      "0.01 0.75\n",
      "0.1 0.8289473684210527\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "j = 0\n",
    "colors = ['r', 'b', 'g']\n",
    "for item in answers_nn.items():\n",
    "    if item[0] != 'genetic_algorithm':\n",
    "        accuracy = []\n",
    "        for items, rate in zip(item[1], [0.0001, 0.001, 0.01, 0.1]):\n",
    "            print(rate, accuracy_score(items[1], items[2]))\n",
    "            accuracy.append(accuracy_score(items[1], items[2]))\n",
    "        plt.plot(['0.0001', '0.001', '0.01', '0.1'], accuracy, marker='o', color=colors[j], label=item[0])\n",
    "            \n",
    "    j += 1\n",
    "\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy Score')   \n",
    "plt.legend()\n",
    "plt.savefig('learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.631578947368421\n",
      "0.001 0.47368421052631576\n",
      "0.01 0.6842105263157895\n",
      "0.1 0.4605263157894737\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 0\n",
    "colors = ['r', 'b', 'g']\n",
    "for item in answers_nn.items():\n",
    "    if item[0] == 'genetic_algorithm':\n",
    "        accuracy = []\n",
    "        for items, rate in zip(item[1], [0.0001, 0.001, 0.01, 0.1]):\n",
    "            print(rate, accuracy_score(items[1], items[2]))\n",
    "            accuracy.append(accuracy_score(items[1], items[2]))\n",
    "\n",
    "        plt.plot(['0.2', '0.3', '0.35', '0.4'], accuracy, marker='o', color=colors[j], label=item[0])\n",
    "            \n",
    "    j += 1\n",
    "            \n",
    "plt.xlabel('Mutation Rate')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend()\n",
    "plt.savefig('mutation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7105263157894737"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(answers_nn['simulated_annealing'][1][1], answers_nn['simulated_annealing'][1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     cp_0  cp_1  cp_2  cp_3  slope_0  slope_1  slope_2  ca_0  ca_1  ca_2  \\\n",
       " 179     1     0     0     0        0        1        0     0     1     0   \n",
       " 228     0     0     0     1        0        1        0     1     0     0   \n",
       " 111     0     0     1     0        0        0        1     0     1     0   \n",
       " 246     1     0     0     0        0        1        0     0     0     1   \n",
       " 60      0     0     1     0        0        0        1     0     1     0   \n",
       " 9       0     0     1     0        0        0        1     1     0     0   \n",
       " 119     1     0     0     0        0        1        0     1     0     0   \n",
       " 223     1     0     0     0        1        0        0     0     0     1   \n",
       " 268     1     0     0     0        0        1        0     0     0     1   \n",
       " 33      0     0     1     0        1        0        0     0     1     0   \n",
       " 5       1     0     0     0        0        1        0     1     0     0   \n",
       " 101     0     0     0     1        1        0        0     1     0     0   \n",
       " 45      0     1     0     0        0        0        1     1     0     0   \n",
       " 175     1     0     0     0        0        1        0     1     0     0   \n",
       " 118     0     1     0     0        0        0        1     1     0     0   \n",
       " 46      0     0     1     0        0        0        1     1     0     0   \n",
       " 125     0     1     0     0        0        0        1     1     0     0   \n",
       " 192     1     0     0     0        0        1        0     0     1     0   \n",
       " 285     1     0     0     0        0        1        0     0     0     1   \n",
       " 279     1     0     0     0        0        1        0     0     1     0   \n",
       " 152     0     0     0     1        0        1        0     1     0     0   \n",
       " 269     1     0     0     0        1        0        0     1     0     0   \n",
       " 272     1     0     0     0        0        1        0     1     0     0   \n",
       " 25      0     1     0     0        0        0        1     0     0     1   \n",
       " 146     0     0     1     0        0        1        0     0     1     0   \n",
       " 283     1     0     0     0        0        0        1     1     0     0   \n",
       " 254     0     0     0     1        0        0        1     1     0     0   \n",
       " 73      1     0     0     0        0        0        1     1     0     0   \n",
       " 231     1     0     0     0        0        1        0     0     0     0   \n",
       " 109     1     0     0     0        0        0        1     1     0     0   \n",
       " ..    ...   ...   ...   ...      ...      ...      ...   ...   ...   ...   \n",
       " 281     1     0     0     0        0        1        0     1     0     0   \n",
       " 78      0     1     0     0        0        0        1     1     0     0   \n",
       " 292     1     0     0     0        0        1        0     0     0     1   \n",
       " 232     1     0     0     0        0        1        0     0     1     0   \n",
       " 219     1     0     0     0        0        0        1     0     0     1   \n",
       " 255     1     0     0     0        0        1        0     0     0     0   \n",
       " 63      0     1     0     0        0        1        0     1     0     0   \n",
       " 82      0     0     1     0        0        0        1     0     1     0   \n",
       " 236     1     0     0     0        0        0        1     0     0     1   \n",
       " 204     1     0     0     0        1        0        0     0     0     0   \n",
       " 249     0     0     1     0        0        1        0     0     0     0   \n",
       " 104     0     0     1     0        0        0        1     1     0     0   \n",
       " 300     1     0     0     0        0        1        0     0     0     1   \n",
       " 193     1     0     0     0        0        1        0     0     0     1   \n",
       " 184     1     0     0     0        0        1        0     1     0     0   \n",
       " 132     0     1     0     0        0        0        1     1     0     0   \n",
       " 202     1     0     0     0        0        0        1     1     0     0   \n",
       " 196     0     0     1     0        0        1        0     1     0     0   \n",
       " 75      0     1     0     0        0        1        0     1     0     0   \n",
       " 176     1     0     0     0        0        0        1     0     0     1   \n",
       " 59      1     0     0     0        0        0        1     0     1     0   \n",
       " 93      0     1     0     0        0        0        1     0     1     0   \n",
       " 6       0     1     0     0        0        1        0     1     0     0   \n",
       " 177     0     0     1     0        0        0        1     1     0     0   \n",
       " 30      0     1     0     0        0        0        1     0     1     0   \n",
       " 22      1     0     0     0        0        0        1     1     0     0   \n",
       " 258     1     0     0     0        0        1        0     1     0     0   \n",
       " 56      1     0     0     0        0        0        1     1     0     0   \n",
       " 242     1     0     0     0        0        1        0     0     0     1   \n",
       " 114     0     1     0     0        0        0        1     1     0     0   \n",
       " \n",
       "        ...     thals_3       age  sex  trestbps      chol  fbs  restecg  \\\n",
       " 179    ...           0  0.583333    1  0.528302  0.342466    0      0.0   \n",
       " 228    ...           1  0.625000    1  0.716981  0.369863    0      0.0   \n",
       " 111    ...           1  0.583333    1  0.528302  0.000000    1      0.5   \n",
       " 246    ...           1  0.562500    0  0.377358  0.646119    0      0.0   \n",
       " 60     ...           0  0.875000    0  0.150943  0.317352    1      0.0   \n",
       " 9      ...           0  0.583333    1  0.528302  0.095890    0      0.5   \n",
       " 119    ...           0  0.354167    0  0.415094  0.267123    0      0.0   \n",
       " 223    ...           1  0.562500    0  1.000000  0.369863    1      0.0   \n",
       " 268    ...           0  0.520833    1  0.264151  0.365297    0      0.0   \n",
       " 33     ...           0  0.520833    1  0.292453  0.335616    0      0.0   \n",
       " 5      ...           0  0.583333    1  0.433962  0.150685    0      0.5   \n",
       " 101    ...           1  0.625000    1  0.792453  0.328767    0      0.0   \n",
       " 45     ...           0  0.479167    1  0.245283  0.454338    0      0.5   \n",
       " 175    ...           1  0.229167    1  0.150943  0.093607    0      0.0   \n",
       " 118    ...           0  0.354167    0  0.103774  0.178082    0      0.5   \n",
       " 46     ...           0  0.312500    1  0.433962  0.248858    0      0.0   \n",
       " 125    ...           0  0.104167    0  0.226415  0.191781    0      0.5   \n",
       " 192    ...           1  0.520833    1  0.245283  0.141553    0      0.5   \n",
       " 285    ...           1  0.354167    1  0.433962  0.422374    0      0.5   \n",
       " 279    ...           0  0.666667    1  0.415094  0.091324    0      0.0   \n",
       " 152    ...           1  0.729167    1  0.716981  0.230594    0      0.0   \n",
       " 269    ...           1  0.562500    1  0.339623  0.358447    1      0.0   \n",
       " 272    ...           0  0.791667    1  0.245283  0.253425    0      0.5   \n",
       " 25     ...           0  0.875000    0  0.622642  0.401826    0      0.5   \n",
       " 146    ...           0  0.312500    0  0.226415  0.264840    0      0.5   \n",
       " 283    ...           1  0.229167    1  0.547170  0.221461    0      0.5   \n",
       " 254    ...           0  0.625000    1  0.622642  0.335616    0      0.0   \n",
       " 73     ...           0  0.458333    1  0.433962  0.308219    0      0.0   \n",
       " 231    ...           1  0.583333    1  0.669811  0.372146    1      0.0   \n",
       " 109    ...           0  0.437500    0  0.150943  0.292237    0      0.0   \n",
       " ..     ...         ...       ...  ...       ...       ...  ...      ...   \n",
       " 281    ...           0  0.479167    1  0.320755  0.178082    1      0.5   \n",
       " 78     ...           0  0.479167    1  0.320755  0.180365    1      0.5   \n",
       " 292    ...           0  0.604167    0  0.716981  0.226027    1      0.0   \n",
       " 232    ...           1  0.541667    1  0.622642  0.372146    0      0.0   \n",
       " 219    ...           1  0.395833    1  0.339623  0.296804    1      0.0   \n",
       " 255    ...           1  0.333333    1  0.452830  0.417808    0      0.0   \n",
       " 63     ...           0  0.250000    1  0.386792  0.175799    0      0.5   \n",
       " 82     ...           0  0.645833    0  0.075472  0.438356    0      0.5   \n",
       " 236    ...           1  0.604167    1  0.292453  0.397260    0      0.0   \n",
       " 204    ...           1  0.687500    0  0.622642  0.086758    0      0.0   \n",
       " 249    ...           1  0.833333    1  0.433962  0.292237    0      0.0   \n",
       " 104    ...           0  0.437500    1  0.330189  0.159817    0      0.5   \n",
       " 300    ...           1  0.812500    1  0.471698  0.152968    1      0.5   \n",
       " 193    ...           1  0.645833    1  0.481132  0.356164    0      0.0   \n",
       " 184    ...           1  0.437500    1  0.528302  0.267123    0      0.0   \n",
       " 132    ...           0  0.270833    1  0.245283  0.385845    0      0.5   \n",
       " 202    ...           1  0.604167    1  0.528302  0.328767    0      0.0   \n",
       " 196    ...           0  0.354167    1  0.528302  0.239726    0      0.5   \n",
       " 75     ...           0  0.541667    0  0.386792  0.283105    0      0.0   \n",
       " 176    ...           1  0.645833    1  0.216981  0.237443    1      0.5   \n",
       " 59     ...           0  0.583333    0  0.320755  0.404110    0      0.0   \n",
       " 93     ...           0  0.520833    0  0.358491  0.369863    1      0.0   \n",
       " 6      ...           0  0.562500    0  0.433962  0.383562    0      0.0   \n",
       " 177    ...           0  0.729167    1  0.433962  0.477169    0      0.5   \n",
       " 30     ...           0  0.250000    0  0.103774  0.164384    0      0.5   \n",
       " 22     ...           0  0.270833    1  0.433962  0.228311    0      0.5   \n",
       " 258    ...           0  0.687500    0  0.528302  0.269406    0      0.5   \n",
       " 56     ...           0  0.395833    1  0.264151  0.219178    0      0.0   \n",
       " 242    ...           0  0.729167    1  0.481132  0.196347    0      0.0   \n",
       " 114    ...           0  0.541667    1  0.339623  0.310502    0      0.5   \n",
       " \n",
       "       thalach  exang   oldpeak  \n",
       " 179  0.312977      1  0.096774  \n",
       " 228  0.671756      0  0.032258  \n",
       " 111  0.778626      0  0.032258  \n",
       " 246  0.603053      1  0.306452  \n",
       " 60   0.450382      0  0.000000  \n",
       " 9    0.786260      0  0.258065  \n",
       " 119  0.618321      1  0.000000  \n",
       " 223  0.473282      1  0.645161  \n",
       " 268  0.343511      1  0.516129  \n",
       " 33   0.618321      0  0.080645  \n",
       " 5    0.587786      0  0.064516  \n",
       " 101  0.564885      0  0.677419  \n",
       " 45   0.770992      0  0.032258  \n",
       " 175  0.328244      1  0.322581  \n",
       " 118  0.770992      0  0.000000  \n",
       " 46   0.832061      0  0.000000  \n",
       " 125  0.923664      0  0.112903  \n",
       " 192  0.320611      0  0.225806  \n",
       " 285  0.374046      1  0.290323  \n",
       " 279  0.412214      1  0.580645  \n",
       " 152  0.641221      0  0.096774  \n",
       " 269  0.244275      1  0.258065  \n",
       " 272  0.000000      0  0.161290  \n",
       " 25   0.694656      0  0.064516  \n",
       " 146  0.595420      0  0.048387  \n",
       " 283  0.839695      0  0.000000  \n",
       " 254  0.412214      0  0.000000  \n",
       " 73   0.877863      1  0.000000  \n",
       " 231  0.404580      0  0.161290  \n",
       " 109  0.671756      0  0.000000  \n",
       " ..        ...    ...       ...  \n",
       " 281  0.648855      1  0.161290  \n",
       " 78   0.862595      0  0.000000  \n",
       " 292  0.572519      1  0.451613  \n",
       " 232  0.564885      1  0.129032  \n",
       " 219  0.603053      1  0.000000  \n",
       " 255  0.580153      1  0.000000  \n",
       " 63   0.465649      0  0.000000  \n",
       " 82   0.679389      0  0.000000  \n",
       " 236  0.763359      0  0.000000  \n",
       " 204  0.564885      0  1.000000  \n",
       " 249  0.572519      0  0.322581  \n",
       " 104  0.702290      0  0.000000  \n",
       " 300  0.534351      0  0.548387  \n",
       " 193  0.541985      1  0.451613  \n",
       " 184  0.435115      0  0.419355  \n",
       " 132  0.694656      0  0.000000  \n",
       " 202  0.305344      1  0.129032  \n",
       " 196  0.580153      0  0.580645  \n",
       " 75   0.687023      0  0.225806  \n",
       " 176  0.679389      1  0.225806  \n",
       " 59   0.671756      0  0.000000  \n",
       " 93   0.671756      1  0.000000  \n",
       " 6    0.625954      0  0.209677  \n",
       " 177  0.664122      0  0.000000  \n",
       " 30   0.740458      0  0.000000  \n",
       " 22   0.816794      0  0.000000  \n",
       " 258  0.633588      1  0.225806  \n",
       " 56   0.877863      0  0.000000  \n",
       " 242  0.465649      0  0.322581  \n",
       " 114  0.641221      0  0.000000  \n",
       " \n",
       " [76 rows x 25 columns], array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1]]),      target\n",
       " 179       0\n",
       " 228       0\n",
       " 111       1\n",
       " 246       0\n",
       " 60        1\n",
       " 9         1\n",
       " 119       1\n",
       " 223       0\n",
       " 268       0\n",
       " 33        1\n",
       " 5         1\n",
       " 101       1\n",
       " 45        1\n",
       " 175       0\n",
       " 118       1\n",
       " 46        1\n",
       " 125       1\n",
       " 192       0\n",
       " 285       0\n",
       " 279       0\n",
       " 152       1\n",
       " 269       0\n",
       " 272       0\n",
       " 25        1\n",
       " 146       1\n",
       " 283       0\n",
       " 254       0\n",
       " 73        1\n",
       " 231       0\n",
       " 109       1\n",
       " ..      ...\n",
       " 281       0\n",
       " 78        1\n",
       " 292       0\n",
       " 232       0\n",
       " 219       0\n",
       " 255       0\n",
       " 63        1\n",
       " 82        1\n",
       " 236       0\n",
       " 204       0\n",
       " 249       0\n",
       " 104       1\n",
       " 300       0\n",
       " 193       0\n",
       " 184       0\n",
       " 132       1\n",
       " 202       0\n",
       " 196       0\n",
       " 75        1\n",
       " 176       0\n",
       " 59        1\n",
       " 93        1\n",
       " 6         1\n",
       " 177       0\n",
       " 30        1\n",
       " 22        1\n",
       " 258       0\n",
       " 56        1\n",
       " 242       0\n",
       " 114       1\n",
       " \n",
       " [76 rows x 1 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_nn['simulated_annealing'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
